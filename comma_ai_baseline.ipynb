{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "\n",
    "def video_to_frames(input_loc, output_loc):\n",
    "    try:\n",
    "        os.mkdir(output_loc)\n",
    "    except OSError:\n",
    "        pass\n",
    "    # Log the time\n",
    "    time_start = time.time()\n",
    "    # Start capturing the feed\n",
    "    cap = cv2.VideoCapture(input_loc)\n",
    "    # Find the number of frames\n",
    "    video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - 1\n",
    "    print (\"Number of frames: \", video_length)\n",
    "    count = 0\n",
    "    print (\"Converting video..\\n\")\n",
    "    # Start converting the video\n",
    "    while cap.isOpened():\n",
    "        # Extract the frame\n",
    "        ret, frame = cap.read()\n",
    "        # Write the results back to output location.\n",
    "        cv2.imwrite(output_loc + \"/%#05d.jpg\" % (count+1), frame)\n",
    "        count = count + 1\n",
    "        # If there are no more frames left\n",
    "        if (count > (video_length-1)):\n",
    "            # Log the time again\n",
    "            time_end = time.time()\n",
    "            # Release the feed\n",
    "            cap.release()\n",
    "            # Print stats\n",
    "            print (\"Done extracting frames.\\n%d frames extracted\" % count)\n",
    "            print (\"It took %d seconds forconversion.\" % (time_end-time_start))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_to_frames(vid_dir + 'train.mp4', './commaai/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_dir = './commaai/'\n",
    "test_path = './commaai/test/'\n",
    "train_path = './commaai/data/train/'\n",
    "valid_path = './commaai/data/valid/'\n",
    "data_dir = './commaai/data/'\n",
    "\n",
    "with open(vid_dir + 'train.txt', 'r', encoding='ISO-8859-1') as fh:\n",
    "    lister = fh.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure we take the data in sequence\n",
    "def make_val_set(PATH, p):\n",
    "    PATH = PATH if PATH[-1] == '/' else PATH+'/'\n",
    "    list_of_files = sorted(os.listdir(f\"{vid_dir}train/\"))\n",
    "    n_idxs = len(list_of_files) * (1 - p)\n",
    "    selected_files = list_of_files[int(n_idxs):]\n",
    "    for file in selected_files:\n",
    "        try:\n",
    "            os.rename(f\"{PATH}train/{file}\", f\"{PATH}valid/{file}\")\n",
    "        except FileNotFoundError as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_val_set(data_dir, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = [x for x in range(18000, 20398, 1)] # grab ~10% of images for val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speed(img_name):\n",
    "    img_name = str(img_name)\n",
    "    img_only = img_name.replace('commaai/data/train/', '')\n",
    "    idx = int(img_only.replace('.jpg',''))\n",
    "    return float(lister[idx].replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeder = DataBlock(\n",
    "    blocks=(ImageBlock, RegressionBlock),\n",
    "    get_items=get_image_files,\n",
    "    get_y=get_speed,\n",
    "    splitter=IndexSplitter(idxs),\n",
    "    batch_tfms=[*aug_transforms(size=(240,320)), \n",
    "                Normalize.from_stats(*imagenet_stats)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = speeder.dataloaders(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet34, metrics=rmse)\n",
    "learn.loss = MSELossFlat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
